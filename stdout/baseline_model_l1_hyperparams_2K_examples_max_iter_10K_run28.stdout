[nltk_data] Downloading package stopwords to
[nltk_data]     /home1/i/irebecca/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package punkt to
[nltk_data]     /home1/i/irebecca/nltk_data...
[nltk_data]   Package punkt is already up-to-date!

---argparser---:
notes l1 hyperparameters, 2K examples, max_iter=10K. 	 <class 'str'>
outDir out/ 	 <class 'str'>
dataDir data/ 	 <class 'str'>

---train fnames---
len: 6
data/train.choices.pkl
data/train.choices.txt
data/train.pkl
data/train_comments.tok.32000.txt
data/train_comments.tok.txt
data/train_comments.txt

---val fnames---
len: 6
data/val.choices.pkl
data/val.choices.txt
data/val.pkl
data/val_comments.tok.32000.txt
data/val_comments.tok.txt
data/val_comments.txt

---test fnames---
len: 6
data/test.choices.pkl
data/test.choices.txt
data/test.pkl
data/test_comments.tok.32000.txt
data/test_comments.tok.txt
data/test_comments.txt

---TRAIN EXAMPLES---
board_feature_matrix.shape: (209566, 364)
Time elapsed making board feature matrix:	00:04:08
text_feature_matrix.shape: (209566, 1000)
Time elapsed making text feature matrix:	00:00:10
boards_mat.shape: (209566, 364)
len(text_mat): 209566
cur fname: data/train.choices.txt

X num_examples: (419132, 1364)	y num_examples: (419132,)
Time elapsed getting examples:	00:00:07

---VALIDATION EXAMPLES---
board_feature_matrix.shape: (20676, 364)
Time elapsed making board feature matrix:	00:00:25
text_feature_matrix.shape: (20676, 1000)
Time elapsed making text feature matrix:	00:00:01
boards_mat.shape: (20676, 364)
len(text_mat): 20676
cur fname: data/val.choices.txt

X num_examples: (41352, 1364)	y num_examples: (41352,)
Time elapsed getting examples:	00:00:00

---TEST EXAMPLES---
board_feature_matrix.shape: (91468, 364)
Time elapsed making board feature matrix:	00:01:53
text_feature_matrix.shape: (91468, 1000)
Time elapsed making text feature matrix:	00:00:04
boards_mat.shape: (91468, 364)
len(text_mat): 91468
cur fname: data/test.choices.txt

X num_examples: (182936, 1364)	y num_examples: (182936,)
Time elapsed getting examples:	00:00:03

---TRAIN+VALIDATION COMBINED EXAMPLES FOR AUTOGRID SEARCH---
boards_mat.shape: (209566, 364)
len(text_mat): 209566
cur fname: data/train.choices.txt

boards_mat.shape: (20676, 364)
len(text_mat): 20676
cur fname: data/val.choices.txt

X num_examples: (460484, 1364)	y num_examples: (460484,)
Time elapsed getting examples:	00:00:08

---Logistic Regression Auto Grid In Progress---
starting auto parameter search..

# Tuning hyper-parameters for precision


Best parameters set found on development set:


{'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}


Grid scores on development set:


0.250 (+/-0.000) for {'C': 0.001, 'penalty': 'l1', 'solver': 'liblinear'}
0.732 (+/-0.019) for {'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'}
0.946 (+/-0.028) for {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}
0.987 (+/-0.006) for {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}
0.984 (+/-0.005) for {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}


Detailed classification report:


The model is trained on the full development set.
The scores are computed on the full evaluation set.


              precision    recall  f1-score   support

           0       0.48      0.46      0.47     91468
           1       0.48      0.50      0.49     91468

    accuracy                           0.48    182936
   macro avg       0.48      0.48      0.48    182936
weighted avg       0.48      0.48      0.48    182936




# Tuning hyper-parameters for recall


Best parameters set found on development set:


{'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}


Grid scores on development set:


0.500 (+/-0.000) for {'C': 0.001, 'penalty': 'l1', 'solver': 'liblinear'}
0.725 (+/-0.018) for {'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'}
0.944 (+/-0.028) for {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}
0.986 (+/-0.007) for {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}
0.983 (+/-0.006) for {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}


Detailed classification report:


The model is trained on the full development set.
The scores are computed on the full evaluation set.


              precision    recall  f1-score   support

           0       0.48      0.46      0.47     91468
           1       0.48      0.50      0.49     91468

    accuracy                           0.48    182936
   macro avg       0.48      0.48      0.48    182936
weighted avg       0.48      0.48      0.48    182936




# Tuning hyper-parameters for f1


Best parameters set found on development set:


{'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}


Grid scores on development set:


0.333 (+/-0.000) for {'C': 0.001, 'penalty': 'l1', 'solver': 'liblinear'}
0.723 (+/-0.019) for {'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'}
0.944 (+/-0.028) for {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}
0.986 (+/-0.007) for {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}
0.983 (+/-0.006) for {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}


Detailed classification report:


The model is trained on the full development set.
The scores are computed on the full evaluation set.


              precision    recall  f1-score   support

           0       0.48      0.46      0.47     91468
           1       0.48      0.50      0.49     91468

    accuracy                           0.48    182936
   macro avg       0.48      0.48      0.48    182936
weighted avg       0.48      0.48      0.48    182936



end auto parameter search..
Time elapsed in doing an automatic parameter search:	00:00:11

test_accuracy: 0.48148822132347524	test_best_score: 0.9864971024270283

---Results---
*test*	best_model: {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}	accuracy: 0.48148822132347524
Time elapsed in main:	00:07:26
